{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "torch_framework.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnqFSVUd-_fA"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhtCl1G8-_fC"
      },
      "source": [
        "## loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY38RjTT-_fC"
      },
      "source": [
        "def extract_distinct_labels(group_labels):\n",
        "    '''\n",
        "    compute labels dictionary\n",
        "    {\n",
        "        'type 1': [sample_start_position_1, sample_end_position_1],\n",
        "        'type 2': [sample_start_position_2, sample_end_position_2],\n",
        "        ...\n",
        "    }\n",
        "    '''\n",
        "    all_labels = {}\n",
        "    for i, label in enumerate(group_labels):\n",
        "        if label not in all_labels:\n",
        "            all_labels[label] = [i]\n",
        "        if i == len(group_labels)-1 or group_labels[i+1] not in all_labels:\n",
        "            all_labels[label].append(i+1)\n",
        "    return all_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDcekBTh-_fC"
      },
      "source": [
        "def calculate_centers_SRW(P, all_labels):\n",
        "    '''\n",
        "    compute group centers, adapted from SRW centroid() function\n",
        "    \n",
        "    return a tensor with group centroids\n",
        "    if we have k groups and n nodes, then C.shape = (k, n)\n",
        "    '''\n",
        "    C = torch.zeros(size=(len(all_labels), P.shape[1]))\n",
        "    count = 0\n",
        "    for label in all_labels:\n",
        "        start, end = all_labels[label]\n",
        "        C[count,:] = torch.sum(P[start: end, :], axis = 0) / (end - start)\n",
        "        count += 1\n",
        "    return C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmMVKCuD-_fC"
      },
      "source": [
        "def label_to_id(all_labels):\n",
        "    '''\n",
        "    mapping label string to id\n",
        "     {\n",
        "        'type 1': 0,\n",
        "        'type 2': 1,\n",
        "        ...\n",
        "    }\n",
        "    \n",
        "    '''\n",
        "    label_id = {}\n",
        "    count = 0\n",
        "    for label in all_labels:\n",
        "        label_id[label] = count\n",
        "        count += 1\n",
        "    return label_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlZoMY6G-_fC"
      },
      "source": [
        "def loss(lambda_value, params, beta, P, group_labels, all_labels, is_train):\n",
        "    '''\n",
        "    This function computes loss function adapted from SRW cost_func_WMW()\n",
        "    '''\n",
        "    \n",
        "    '''l2 norm'''\n",
        "    loss_value = None\n",
        "    for param in params:\n",
        "        if loss_value is None:\n",
        "            loss_value = lambda_value * torch.norm(param, p=2)\n",
        "        else:\n",
        "            loss_value += lambda_value * torch.norm(param, p=2)\n",
        "    accuracy = 0.0\n",
        "    \n",
        "    '''retrieve centers'''\n",
        "    C = calculate_centers_SRW(P, all_labels)\n",
        "    \n",
        "    '''retrieve ids for group labels'''\n",
        "    label_id = label_to_id(all_labels)\n",
        "    \n",
        "    '''necessary intermediate value for computing loss'''\n",
        "    P_dot_CT = torch.matmul(P, C.T)\n",
        "    C_dot_CT = torch.matmul(C, C.T)\n",
        "    P_dot_PT = torch.matmul(P, P.T)\n",
        "    \n",
        "    '''simply copy from SRW cost_func_WMW()'''\n",
        "    for u in range(P.shape[0]):\n",
        "        x_u = torch.tensor(-2.0)\n",
        "        i = label_id[group_labels[u]]\n",
        "        start, end = all_labels[group_labels[u]]\n",
        "        group_sample = end - start\n",
        "        if is_train == False:\n",
        "            coeff = max((group_sample / (group_sample - 1)) ** 2, 1.0)\n",
        "        else:\n",
        "            coeff = 1.0\n",
        "        dist_ui = coeff *(P_dot_PT[u,u] - 2 * P_dot_CT[u, i] + C_dot_CT[i,i])\n",
        "        for label in label_id:\n",
        "            if label != group_labels[u]:\n",
        "                j = label_id[label]\n",
        "                x_u_tmp = dist_ui -(P_dot_PT[u,u] - 2 * P_dot_CT[u,j] + C_dot_CT[j,j])\n",
        "                if x_u_tmp > x_u:\n",
        "                    x_u = x_u_tmp\n",
        "        '''if correctly classified, increase accuracy'''\n",
        "        if x_u < 0.0:\n",
        "            accuracy += 1.0\n",
        "        loss_value += 1. / (1+torch.exp(-x_u / beta))\n",
        "    return loss_value, accuracy / P.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zYPHI3V-_fC"
      },
      "source": [
        "## Model class implement with pytorch\n",
        "* train with simple gradient descent\n",
        "* add validation module \n",
        "* add Adam update\n",
        "* support MLP in activation module\n",
        "* support Sigmoid and ReLu activation in MLP\n",
        "* support Softplus and Gaussian activation in MLP\n",
        "* support Nesterov update method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRi30wDS-_fC"
      },
      "source": [
        "class SRW_pytorch:\n",
        "    def __init__(self, n_iter, lambda_value, beta, features, edges, group_labels_train, P_train, group_labels_val, P_val, betas, layers, params, rst_prob, lr, update = 'Adam'):\n",
        "        self.n_iter = n_iter #number of iterations for training'''\n",
        "        self.lambda_value = lambda_value #coefficient for l1 norm regularization'''\n",
        "        self.beta = beta #parameter for loss function'''\n",
        "        self.features = features #features of training dataset'''\n",
        "        self.edges = edges #edges of training dataset'''\n",
        "        self.group_labels_train = group_labels_train #labels of training dataset'''\n",
        "        self.P_train = P_train #initialized P matrix'''\n",
        "        self.group_labels_val = group_labels_val #labels of training dataset'''\n",
        "        self.P_val = P_val #initialized P matrix'''\n",
        "        self.rst_prob = rst_prob #random walk reset probabilities'''\n",
        "        self.lr = lr #learning rate'''\n",
        "        self.params = params #params for MLP activation\n",
        "        self.layers = layers\n",
        "        self.state = [{'m_t': torch.zeros(p.shape), 'v_t': torch.zeros(p.shape)} for p in self.params] #used for adam update\n",
        "        self.betas = betas # hard code for now\n",
        "        self.eps = 1e-8 # hard code for now\n",
        "        self.update = update\n",
        "        \n",
        "    def train(self):\n",
        "        for t in range(n_iter):\n",
        "            '''compute edge strength, sigmoid activation'''\n",
        "            \n",
        "            strength = self.activation()\n",
        "\n",
        "            '''create transition matrix Q'''\n",
        "            Q = torch.zeros(size=(self.P_train.shape[1], self.P_train.shape[1]))\n",
        "            for j in range(strength.shape[0]):\n",
        "                Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
        "\n",
        "            '''normalize Q'''\n",
        "            Q = Q / (torch.sum(Q, axis = 1) + self.eps).reshape(-1,1)\n",
        "            \n",
        "            '''noramlize P'''\n",
        "            P_init = self.P_train / (torch.sum(self.P_train, axis = 1) + self.eps).reshape(-1,1)\n",
        "\n",
        "            '''create P matrix for random walk'''\n",
        "            P = P_init.detach().clone()\n",
        "            \n",
        "            '''for test, only peform random walk 30 times (should be enough to converge)''' \n",
        "            \n",
        "            for j in range(40):\n",
        "                P = (1.0-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
        "            '''compute loss and backward()'''\n",
        "            all_labels = extract_distinct_labels(self.group_labels_train)\n",
        "            loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, self.group_labels_train, all_labels, True)\n",
        "            loss_value.backward(retain_graph = True)\n",
        "            \n",
        "            '''update parameters'''\n",
        "            self.step(t+1)\n",
        "            for i in range(len(self.params)):\n",
        "                self.params[i].grad.zero_()\n",
        "\n",
        "            print(\"[%d/%d] training loss: %.4f\\t training accuracy: %.4f\" %(t+1, n_iter, loss_value.data, accuracy))\n",
        "\n",
        "            loss_value_val, accuracy_val = self.validation()\n",
        "            print(\"[%d/%d] validation loss: %.4f\\t validation accuracy: %.4f\" %(t+1, n_iter, loss_value_val.data, accuracy_val))\n",
        "            \n",
        "            \n",
        "    \n",
        "    def activation(self):\n",
        "        strength = self.features\n",
        "        for i in range(len(self.params)):\n",
        "            if self.layers[i] == 'sigmoid':\n",
        "                strength = 1.0 / (1.0 + torch.exp(-torch.matmul(strength, self.params[i])))\n",
        "            elif self.layers[i] == 'ReLu':\n",
        "                strength = torch.nn.functional.relu(torch.matmul(strength, self.params[i]))\n",
        "            elif self.layers[i] == 'softplus':\n",
        "                strength = torch.log(1.0 + torch.exp(torch.matmul(strength, self.params[i])))\n",
        "            elif self.layers[i] == 'gaussian':\n",
        "                strength = torch.exp(-torch.matmul(strength, self.params[i]) ** 2)\n",
        "            else:\n",
        "                raise NotImplementedError(\"%s layer has not implemented yet\" %(self.layer[i]))\n",
        "                \n",
        "        return strength\n",
        "    \n",
        "    def step(self, t):\n",
        "        if self.update == 'Adam':\n",
        "            b1, b2 = self.betas\n",
        "\n",
        "            B1 = 1.0 - np.power(b1, t)\n",
        "            B2 = 1.0 - np.power(b2, t)\n",
        "            \n",
        "            for i in range(len(self.params)):\n",
        "                self.state[i]['m_t'] = b1 * self.state[i]['m_t'] + (1 - b1) * self.params[i].grad.data\n",
        "                self.state[i]['v_t'] = b2 * self.state[i]['v_t'] + (1 - b2) * (self.params[i].grad.data ** 2)\n",
        "                st = self.lr / B1\n",
        "                D = torch.sqrt(self.state[i]['v_t'] / B2) + self.eps\n",
        "                self.params[i].data = self.params[i].data - self.state[i]['m_t'] / D * st\n",
        "        elif self.update == 'GD':\n",
        "            for i in range(len(self.params)):\n",
        "                self.params[i].data -= self.lr * self.params[i].grad.data\n",
        "        elif self.update == 'Nesterov':\n",
        "            for i in range(len(self.params)):\n",
        "                prev = self.state[i]['m_t'].detach().clone()\n",
        "                self.state[i]['m_t'] = 0.9 * self.state[i]['m_t'] - self.lr * self.params[i].grad.data\n",
        "                self.params[i].data = -0.9 * prev + self.state[i]['m_t'] * 1.9\n",
        "        else:\n",
        "            raise NotImplementedError(\"%s optimization method has not implemented yet\" %(self.update))\n",
        "        \n",
        "    def validation(self):\n",
        "        strength = self.activation()\n",
        "        \n",
        "        Q = torch.zeros(size=(self.P_val.shape[1], self.P_val.shape[1]))\n",
        "        for j in range(strength.shape[0]):\n",
        "            Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
        "        Q = Q / (torch.sum(Q, axis = 1) + self.eps).reshape(-1,1)\n",
        "        P_init = self.P_val / (torch.sum(self.P_val, axis = 1) + self.eps).reshape(-1,1)\n",
        "        P = P_init.detach().clone()\n",
        "        for j in range(40):\n",
        "            P = (1-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
        "        \n",
        "        all_labels = extract_distinct_labels(self.group_labels_val)\n",
        "        loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, self.group_labels_val, all_labels, False)\n",
        "        \n",
        "        return loss_value, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXtcBZa5-_fC"
      },
      "source": [
        "## Real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCtK9VY9-_fC"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R76W9Sx-_fC"
      },
      "source": [
        "import pandas as pd\n",
        "import SRW_v044 as SRW\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibAKJgzg-_fD"
      },
      "source": [
        "#### loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUruAvJp-_fD",
        "outputId": "1d8320ff-0493-45e8-bddd-8aa3eeb48f11"
      },
      "source": [
        "edges, features, node_names = SRW.load_network('data/BRCA_edge2features_2.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rARqSo3b-_fE",
        "outputId": "2b569b44-a979-42a7-fc34-3f9a9e5e56d5"
      },
      "source": [
        "P_init_train, sample_names_train = SRW.load_samples('data/BRCA_training_data_2.txt', node_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvQsg1IA-_fE",
        "outputId": "18e0bc9c-08c2-4946-c3d0-26d249bca59b"
      },
      "source": [
        "P_init_val, sample_names_val = SRW.load_samples('data/BRCA_validation_data_2.txt', node_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DewNMiTP-_fE"
      },
      "source": [
        "group_labels_train = SRW.load_grouplabels('data/BRCA_training_lables_2.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfq04Nex-_fE"
      },
      "source": [
        "group_labels_val = SRW.load_grouplabels('data/BRCA_validation_lables_2.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jKb4o2o-_fE"
      },
      "source": [
        "#### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKO_FEQq-_fE"
      },
      "source": [
        "def sort_argsort(seq):\n",
        "    argsort_seq = [i for (v, i) in sorted((v, i) for (i, v) in enumerate(seq))]\n",
        "    seq.sort()\n",
        "    return seq, argsort_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuI1doD--_fE"
      },
      "source": [
        "group_labels_train, group_labels_train_argsort = sort_argsort(group_labels_train)\n",
        "group_labels_val, group_labels_val_argsort = sort_argsort(group_labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp27oek--_fF"
      },
      "source": [
        "P_init_train = P_init_train.toarray()[group_labels_train_argsort,:]\n",
        "P_init_val = P_init_val.toarray()[group_labels_val_argsort,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGFfGezU-_fF"
      },
      "source": [
        "#### initialize tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urQnHX1P-_fF"
      },
      "source": [
        "P_init_train = torch.tensor(P_init_train, requires_grad = True, dtype = torch.float32)\n",
        "features = torch.tensor(features.toarray(), requires_grad = True, dtype = torch.float32)\n",
        "P_init_val = torch.tensor(P_init_val, requires_grad = False, dtype = torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmV4_72O-_fF"
      },
      "source": [
        "#### run framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPByT1Ve-_fF"
      },
      "source": [
        "n_iter = 200\n",
        "lambda_value = 0.1\n",
        "beta = 2e-4\n",
        "adam_betas = (0.9, 0.999)\n",
        "rst_prob = 0.3\n",
        "lr = 4e-3\n",
        "w1 = torch.normal(mean = 0, std = 1, size = (features.shape[1], features.shape[1] // 2), requires_grad = True, dtype = torch.float32)\n",
        "w2 = torch.normal(mean = 0, std = 1, size = (features.shape[1] // 2, 1), requires_grad = True, dtype = torch.float32)\n",
        "params = [w1, w2]\n",
        "layers = ['softplus', 'ReLu']\n",
        "solver = SRW_pytorch(n_iter, lambda_value, beta, features, edges, group_labels_train, P_init_train, group_labels_val, P_init_val, adam_betas, layers, params, rst_prob, lr, \"Adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0fBlIQFv-_fF",
        "outputId": "da7f0633-68b8-4ff7-e4db-9a0e2fb3789a"
      },
      "source": [
        "solver.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr3JR9CQSLQ0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}