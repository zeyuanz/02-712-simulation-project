{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import SRW_v044 as SRW\n",
    "import activations\n",
    "from scipy.sparse import csr_matrix, csc_matrix, issparse\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100\n",
    "nnodes = 1000\n",
    "edge_freq = 0.004\n",
    "cliq_edge_freq = 0.114\n",
    "hi_mut_freq = 0.5\n",
    "hi_node = nnodes*3/4\n",
    "group_labels = ['Subtype 1']*(nsamples//2) + ['Subtype 2']*(nsamples//2)\n",
    "feature_names = ['Subnetwork 1', 'Subnetwork 2', 'High mut source', 'High mut target', \n",
    "                 'Random 1', 'Random 2', \n",
    "                 'Self loop', 'Intercept']\n",
    "node_names = ['{}'.format(i) for i in range(1,nnodes+1)]\n",
    "sample_names = ['{}'.format(i) for i in range(1,nsamples+1)]\n",
    "\n",
    "rand_mut_freq = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_prob = 0.3\n",
    "lam = 1e-1\n",
    "WMW_b = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [0]*nnodes\n",
    "edges = []\n",
    "features = [] #(11) cliq1, cliq2, hi_mut_source, hi_mut_target, rand1, rand2, rand3, rand4, rand5, self_loop, intercept\n",
    "for i in range(nnodes-1):\n",
    "    for j in range(i+1,nnodes):\n",
    "        if ((i<100 and j<100) and np.random.random()<cliq_edge_freq) or np.random.random()<edge_freq:\n",
    "            edges.append([i,j])\n",
    "            edges.append([j,i])\n",
    "            features.append([0,0,0,0,np.random.random(),np.random.random(),0,1])\n",
    "            features.append([0,0,0,0,np.random.random(),np.random.random(),0,1])\n",
    "            if (i<50 and j<50):\n",
    "                features[-2][0] = 1\n",
    "                features[-1][0] = 1\n",
    "            if (i>=50 and i<100 and j>=50 and j<100):\n",
    "                features[-2][1] = 1\n",
    "                features[-1][1] = 1\n",
    "            if i == nnodes-1:\n",
    "                features[-2][2] = 1\n",
    "                features[-1][3] = 1\n",
    "            if j == nnodes-1:\n",
    "                features[-2][3] = 1\n",
    "                features[-1][2] = 1\n",
    "            degrees[i] += 1\n",
    "            degrees[j] += 1\n",
    "            \n",
    "\n",
    "for i in range(nnodes):\n",
    "    edges.append([i,i])\n",
    "    features.append([0,0,0,0,np.random.random(),np.random.random(),1,1])\n",
    "\n",
    "P_init = []\n",
    "for p in range(nsamples):\n",
    "    p_init = []\n",
    "    for i in range(nnodes):\n",
    "        freq=0\n",
    "        if p == i:\n",
    "            freq = 1\n",
    "        elif i == hi_node:\n",
    "            freq = hi_mut_freq\n",
    "        elif i<100:\n",
    "            if (max(p,i)<50 or min(p,i)>=50):\n",
    "                freq = 0.015\n",
    "            else:\n",
    "                freq = 0.000\n",
    "        else:\n",
    "            freq = rand_mut_freq\n",
    "\n",
    "        if np.random.random() < freq:\n",
    "            p_init.append(1.0)\n",
    "        else:\n",
    "            p_init.append(0.0)\n",
    "\n",
    "    P_init.append(p_init)\n",
    "    \n",
    "edges_np = np.array(edges)\n",
    "features_csc = csc_matrix(features)\n",
    "P_init_csr = csr_matrix(P_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = torch.tensor(edges)\n",
    "P_init = torch.tensor(P_init, requires_grad = True)\n",
    "features = torch.tensor(features, requires_grad = True, dtype=torch.float64)\n",
    "\n",
    "w_init = np.random.normal(size=(features.shape[1],1))\n",
    "w_init = torch.tensor(w_init, requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_distinct_labels(group_labels):\n",
    "    '''\n",
    "    compute labels dictionary\n",
    "    {\n",
    "        'type 1': [sample_start_position_1, sample_end_position_1],\n",
    "        'type 2': [sample_start_position_2, sample_end_position_2],\n",
    "        ...\n",
    "    }\n",
    "    '''\n",
    "    all_labels = {}\n",
    "    for i, label in enumerate(group_labels):\n",
    "        if label not in all_labels:\n",
    "            all_labels[label] = [i]\n",
    "        if i == len(group_labels)-1 or group_labels[i+1] not in all_labels:\n",
    "            all_labels[label].append(i+1)\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centers_SRW(P, all_labels):\n",
    "    '''\n",
    "    compute group centers, adapted from SRW centroid() function\n",
    "    \n",
    "    return a tensor with group centroids\n",
    "    if we have k groups and n nodes, then C.shape = (k, n)\n",
    "    '''\n",
    "    C = torch.zeros(size=(len(all_labels), P.shape[1]))\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        start, end = all_labels[label]\n",
    "        C[count,:] = torch.sum(P[start: end, :], axis = 0) / (end - start)\n",
    "        count += 1\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_id(all_labels):\n",
    "    '''\n",
    "    mapping label string to id\n",
    "     {\n",
    "        'type 1': 0,\n",
    "        'type 2': 1,\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    label_id = {}\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        label_id[label] = count\n",
    "        count += 1\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(lambda_value, w, beta, P, group_labels, all_labels):\n",
    "    '''\n",
    "    compute loss function adapted from SRW cost_func_WMW()\n",
    "    '''\n",
    "    '''l1 norm'''\n",
    "    loss_value = lambda_value * torch.norm(w, p=1)\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    '''retrieve centers'''\n",
    "    C = calculate_centers_SRW(P, all_labels)\n",
    "    \n",
    "    '''retrieve ids for group labels'''\n",
    "    label_id = label_to_id(all_labels)\n",
    "    \n",
    "    '''necessary intermediate value for computing loss'''\n",
    "    P_dot_CT = torch.matmul(P, C.T)\n",
    "    C_dot_CT = torch.matmul(C, C.T)\n",
    "    \n",
    "    '''simply copy from SRW cost_func_WMW()'''\n",
    "    for u in range(P.shape[0]):\n",
    "        x_u = torch.tensor(-2.0)\n",
    "        i = label_id[group_labels[u]]\n",
    "        dist_ui = -2 * P_dot_CT[u, i] + C_dot_CT[i,i]\n",
    "        for label in label_id:\n",
    "            if label != group_labels[u]:\n",
    "                j = label_id[label]\n",
    "                x_u_tmp = dist_ui + 2*P_dot_CT[u,j] - C_dot_CT[j,j]\n",
    "                if x_u_tmp > x_u:\n",
    "                    x_u = x_u_tmp\n",
    "        '''if correctly classified, increase accuracy'''\n",
    "        if x_u < 0.0:\n",
    "            accuracy += 1.0\n",
    "        loss_value += 1. / (1+torch.exp(-x_u / beta))\n",
    "    return loss_value, accuracy / P.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] loss: 10.6231\t accuracy: 1.0000\n",
      "[2/20] loss: 9.5199\t accuracy: 1.0000\n",
      "[3/20] loss: 8.9824\t accuracy: 1.0000\n",
      "[4/20] loss: 7.5497\t accuracy: 1.0000\n",
      "[5/20] loss: 3.8669\t accuracy: 1.0000\n",
      "[6/20] loss: 1.9650\t accuracy: 1.0000\n",
      "[7/20] loss: 1.7328\t accuracy: 1.0000\n",
      "[8/20] loss: 1.6081\t accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-08c09dcdadfe>\", line 33, in <module>\n",
      "    loss_value.backward(retain_graph = True)\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/torch/tensor.py\", line 185, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 125, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/zeyuanz/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 392, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 381, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 366, in normpath\n",
      "    path = sep.join(comps)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-08c09dcdadfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "'''randomly initialize w'''\n",
    "w_init = np.random.normal(size=(features.shape[1],1))\n",
    "w_init = torch.tensor(w_init, requires_grad = True)\n",
    "lambda_value = 0.1\n",
    "beta = 2e-4\n",
    "for i in range(n_iter):\n",
    "    '''compute edge strength, sigmoid activation'''\n",
    "    strength = 1.0 / (1.0 + torch.exp(-torch.matmul(features, w_init)))\n",
    "    \n",
    "    '''create transition matrix Q'''\n",
    "    Q = torch.zeros(size=(nnodes, nnodes))\n",
    "    for j in range(strength.shape[0]):\n",
    "        Q[edges[j,0],edges[j,1]] = strength[j, 0]\n",
    "        \n",
    "    '''normalize Q'''\n",
    "    Q = Q / (torch.sum(Q, axis = 1) + 1e-8).reshape(-1,1)\n",
    "    \n",
    "    '''noramlize P'''\n",
    "    P_init = P_init / (torch.sum(P_init, axis = 1) + 1e-8).reshape(-1,1)\n",
    "    \n",
    "    '''create P matrix for random walk'''\n",
    "    P = torch.detach(P_init)\n",
    "    P.requires_grad = True\n",
    "    \n",
    "    '''for test, only peform random walk 30 times (should be enough to converge)''' \n",
    "    for j in range(30):\n",
    "        P = (1-rst_prob) * (torch.matmul(P,Q)) + rst_prob * P_init\n",
    "        \n",
    "    '''compute loss and backward()'''\n",
    "    all_labels = extract_distinct_labels(group_labels)\n",
    "    loss_value, accuracy = loss(lambda_value, w_init, beta, P, group_labels, all_labels)\n",
    "    loss_value.backward(retain_graph = True)\n",
    "    \n",
    "    '''simple GD optimization'''\n",
    "    with torch.no_grad():\n",
    "        w_init -= 1.0 * w_init.grad\n",
    "        \n",
    "    '''zero grad'''\n",
    "    w_init.grad.zero_()\n",
    "    print(\"[%d/%d] loss: %.4f\\t accuracy: %.4f\" %(i+1, n_iter, loss_value.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
