{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100\n",
    "nnodes = 1000\n",
    "edge_freq = 0.004\n",
    "cliq_edge_freq = 0.114\n",
    "hi_mut_freq = 0.5\n",
    "hi_node = nnodes*3/4\n",
    "group_labels = ['Subtype 1']*(nsamples//2) + ['Subtype 2']*(nsamples//2)\n",
    "feature_names = ['Subnetwork 1', 'Subnetwork 2', 'High mut source', 'High mut target', \n",
    "                 'Random 1', 'Random 2', \n",
    "                 'Self loop', 'Intercept']\n",
    "node_names = ['{}'.format(i) for i in range(1,nnodes+1)]\n",
    "sample_names = ['{}'.format(i) for i in range(1,nsamples+1)]\n",
    "\n",
    "rand_mut_freq = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [0]*nnodes\n",
    "edges = []\n",
    "features = [] #(11) cliq1, cliq2, hi_mut_source, hi_mut_target, rand1, rand2, rand3, rand4, rand5, self_loop, intercept\n",
    "for i in range(nnodes-1):\n",
    "    for j in range(i+1,nnodes):\n",
    "        if ((i<100 and j<100) and np.random.random()<cliq_edge_freq) or np.random.random()<edge_freq:\n",
    "            edges.append([i,j])\n",
    "            edges.append([j,i])\n",
    "            features.append([0,0,0,0,np.random.random(),np.random.random(),0,1])\n",
    "            features.append([0,0,0,0,np.random.random(),np.random.random(),0,1])\n",
    "            if (i<50 and j<50):\n",
    "                features[-2][0] = 1\n",
    "                features[-1][0] = 1\n",
    "            if (i>=50 and i<100 and j>=50 and j<100):\n",
    "                features[-2][1] = 1\n",
    "                features[-1][1] = 1\n",
    "            if i == nnodes-1:\n",
    "                features[-2][2] = 1\n",
    "                features[-1][3] = 1\n",
    "            if j == nnodes-1:\n",
    "                features[-2][3] = 1\n",
    "                features[-1][2] = 1\n",
    "            degrees[i] += 1\n",
    "            degrees[j] += 1\n",
    "            \n",
    "\n",
    "for i in range(nnodes):\n",
    "    edges.append([i,i])\n",
    "    features.append([0,0,0,0,np.random.random(),np.random.random(),1,1])\n",
    "\n",
    "P_init = []\n",
    "for p in range(nsamples):\n",
    "    p_init = []\n",
    "    for i in range(nnodes):\n",
    "        freq=0\n",
    "        if p == i:\n",
    "            freq = 1\n",
    "        elif i == hi_node:\n",
    "            freq = hi_mut_freq\n",
    "        elif i<100:\n",
    "            if (max(p,i)<50 or min(p,i)>=50):\n",
    "                freq = 0.015\n",
    "            else:\n",
    "                freq = 0.000\n",
    "        else:\n",
    "            freq = rand_mut_freq\n",
    "\n",
    "        if np.random.random() < freq:\n",
    "            p_init.append(1.0)\n",
    "        else:\n",
    "            p_init.append(0.0)\n",
    "\n",
    "    P_init.append(p_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_init = torch.tensor(P_init, requires_grad = True)\n",
    "features = torch.tensor(features, requires_grad = True, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_distinct_labels(group_labels):\n",
    "    '''\n",
    "    compute labels dictionary\n",
    "    {\n",
    "        'type 1': [sample_start_position_1, sample_end_position_1],\n",
    "        'type 2': [sample_start_position_2, sample_end_position_2],\n",
    "        ...\n",
    "    }\n",
    "    '''\n",
    "    all_labels = {}\n",
    "    for i, label in enumerate(group_labels):\n",
    "        if label not in all_labels:\n",
    "            all_labels[label] = [i]\n",
    "        if i == len(group_labels)-1 or group_labels[i+1] not in all_labels:\n",
    "            all_labels[label].append(i+1)\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centers_SRW(P, all_labels):\n",
    "    '''\n",
    "    compute group centers, adapted from SRW centroid() function\n",
    "    \n",
    "    return a tensor with group centroids\n",
    "    if we have k groups and n nodes, then C.shape = (k, n)\n",
    "    '''\n",
    "    C = torch.zeros(size=(len(all_labels), P.shape[1]))\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        start, end = all_labels[label]\n",
    "        C[count,:] = torch.sum(P[start: end, :], axis = 0) / (end - start)\n",
    "        count += 1\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_id(all_labels):\n",
    "    '''\n",
    "    mapping label string to id\n",
    "     {\n",
    "        'type 1': 0,\n",
    "        'type 2': 1,\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    label_id = {}\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        label_id[label] = count\n",
    "        count += 1\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(lambda_value, params, beta, P, group_labels, all_labels, is_train):\n",
    "    '''\n",
    "    This function computes loss function adapted from SRW cost_func_WMW()\n",
    "    '''\n",
    "    \n",
    "    '''l1 norm'''\n",
    "    loss_value = None\n",
    "    for param in params:\n",
    "        if loss_value is None:\n",
    "            loss_value = lambda_value * torch.norm(param, p=1)\n",
    "        else:\n",
    "            loss_value += lambda_value * torch.norm(param, p=1)\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    '''retrieve centers'''\n",
    "    C = calculate_centers_SRW(P, all_labels)\n",
    "    \n",
    "    '''retrieve ids for group labels'''\n",
    "    label_id = label_to_id(all_labels)\n",
    "    \n",
    "    '''necessary intermediate value for computing loss'''\n",
    "    P_dot_CT = torch.matmul(P, C.T)\n",
    "    C_dot_CT = torch.matmul(C, C.T)\n",
    "    P_dot_PT = torch.matmul(P, P.T)\n",
    "    \n",
    "    '''simply copy from SRW cost_func_WMW()'''\n",
    "    for u in range(P.shape[0]):\n",
    "        x_u = torch.tensor(-2.0)\n",
    "        i = label_id[group_labels[u]]\n",
    "        start, end = all_labels[group_labels[u]]\n",
    "        group_sample = end - start\n",
    "        if is_train == False:\n",
    "            coeff = (group_sample / (group_sample - 1)) ** 2\n",
    "        else:\n",
    "            coeff = 1.0\n",
    "        dist_ui = coeff *( P_dot_PT[u,u] -2 * P_dot_CT[u, i] + C_dot_CT[i,i])\n",
    "        for label in label_id:\n",
    "            if label != group_labels[u]:\n",
    "                j = label_id[label]\n",
    "                x_u_tmp = dist_ui -(P_dot_PT[u,u] - 2*P_dot_CT[u,j] + C_dot_CT[j,j])\n",
    "                if x_u_tmp > x_u:\n",
    "                    x_u = x_u_tmp\n",
    "        '''if correctly classified, increase accuracy'''\n",
    "        if x_u < 0.0:\n",
    "            accuracy += 1.0\n",
    "        loss_value += 1. / (1+torch.exp(-x_u / beta))\n",
    "    return loss_value, accuracy / P.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class implement with pytorch\n",
    "* train with simple gradient descent\n",
    "* add validation module \n",
    "* add Adam update\n",
    "* support MLP in activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRW_pytorch:\n",
    "    def __init__(self, n_iter, lambda_value, beta, group_labels, features, edges, P, nnodes, layers, params, rst_prob, lr, update = 'GD'):\n",
    "        self.n_iter = n_iter #number of iterations for training'''\n",
    "        self.lambda_value = lambda_value #coefficient for l1 norm regularization'''\n",
    "        self.beta = beta #parameter for loss function'''\n",
    "        self.group_labels = group_labels #labels of training dataset'''\n",
    "        self.features = features #features of training dataset'''\n",
    "        self.edges = edges #edges of training dataset'''\n",
    "        self.P = P #initialized P matrix'''\n",
    "        self.nnodes = nnodes #number of nodes'''\n",
    "        self.rst_prob = rst_prob #random walk reset probabilities'''\n",
    "        self.lr = lr #learning rate'''\n",
    "        self.is_train = False #has the model been trained'''\n",
    "        self.params = params #params for MLP activation\n",
    "        self.layers = layers\n",
    "        self.state = [{'m_t': torch.zeros(p.shape), 'v_t': torch.zeros(p.shape)} for p in self.params] #used for adam update\n",
    "        self.betas = (0.9, 0.999) # hard code for now\n",
    "        self.eps = 1e-8 # hard code for now\n",
    "        self.update = update\n",
    "        \n",
    "    def train(self):\n",
    "        for t in range(n_iter):\n",
    "            '''compute edge strength, sigmoid activation'''\n",
    "            strength = self.activation()\n",
    "            #strength = 1.0 / (1.0 + torch.exp(-torch.matmul(self.features, self.w)))\n",
    "\n",
    "            '''create transition matrix Q'''\n",
    "            Q = torch.zeros(size=(self.nnodes, self.nnodes))\n",
    "            for j in range(strength.shape[0]):\n",
    "                Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
    "\n",
    "            '''normalize Q'''\n",
    "            Q = Q / (torch.sum(Q, axis = 1) + 1e-8).reshape(-1,1)\n",
    "            \n",
    "            '''noramlize P'''\n",
    "            P_init = self.P / (torch.sum(self.P, axis = 1) + 1e-8).reshape(-1,1)\n",
    "\n",
    "            '''create P matrix for random walk'''\n",
    "            P = torch.detach(P_init)\n",
    "            P.requires_grad = True\n",
    "\n",
    "            '''for test, only peform random walk 30 times (should be enough to converge)''' \n",
    "            for j in range(30):\n",
    "                P = (1-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
    "\n",
    "            '''compute loss and backward()'''\n",
    "            all_labels = extract_distinct_labels(self.group_labels)\n",
    "            loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, self.group_labels, all_labels, self.is_train)\n",
    "            loss_value.backward(retain_graph = True)\n",
    "            \n",
    "            '''update parameters'''\n",
    "            self.step(t+1)\n",
    "            for i in range(len(self.params)):\n",
    "                self.params[i].grad.zero_()\n",
    "            \n",
    "            print(\"[%d/%d] training loss: %.4f\\t training accuracy: %.4f\" %(t+1, n_iter, loss_value.data, accuracy))\n",
    "        self.is_train = True\n",
    "    \n",
    "    def activation(self):\n",
    "        strength = self.features\n",
    "        for i in range(len(self.params)):\n",
    "            if self.layers[i] == 'sigmoid':\n",
    "                strength = 1.0 / (1.0 + torch.exp(-torch.matmul(strength, self.params[i])))\n",
    "            elif self.layers[i] == 'ReLu':\n",
    "                strength = torch.matmul(strength, self.params[i])\n",
    "                strength[strength < 0] = 0\n",
    "            else:\n",
    "                print(\"Layer not implemented yet\")\n",
    "                return\n",
    "                \n",
    "        return strength\n",
    "    \n",
    "    def step(self, t):\n",
    "        if self.update == 'Adam':\n",
    "            b1, b2 = self.betas\n",
    "\n",
    "            B1 = 1.0 - np.power(b1, t)\n",
    "            B2 = 1.0 - np.power(b2, t)\n",
    "            \n",
    "            for i in range(len(self.params)):\n",
    "                self.state[i]['m_t'] = b1 * self.state[i]['m_t'] + (1 - b1) * self.params[i].grad.data\n",
    "                self.state[i]['v_t'] = b2 * self.state[i]['v_t'] + (1 - b2) * (self.params[i].grad.data ** 2)\n",
    "                st = self.lr / B1\n",
    "                D = np.sqrt(self.state[i]['v_t'] / B2) + self.eps\n",
    "                self.params[i].data = self.params[i].data - self.state[i]['m_t'] / D * st\n",
    "        \n",
    "    def validation(self, features_validation, edges_validation, P_validation, group_labels_validation):\n",
    "        if self.is_train == False:\n",
    "            print(\"You should train the model first\")\n",
    "            return\n",
    "        strength = self.activation()\n",
    "        \n",
    "        Q = torch.zeros(size=(self.nnodes, self.nnodes))\n",
    "        for j in range(strength.shape[0]):\n",
    "            Q[edges_validation[j][0], edges_validation[j][1]] = strength[j, 0]\n",
    "        Q = Q / (torch.sum(Q, axis = 1) + 1e-8).reshape(-1,1)\n",
    "        \n",
    "        P = torch.detach(P_validation)\n",
    "        for j in range(30):\n",
    "                P = (1-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_validation\n",
    "        \n",
    "        all_labels = extract_distinct_labels(group_labels_validation)\n",
    "        loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, group_labels_validation, all_labels, self.is_train)\n",
    "        \n",
    "        return loss_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 15\n",
    "lambda_value = 0.1\n",
    "beta = 2e-4\n",
    "rst_prob = 0.3\n",
    "lr = 1.0\n",
    "w1 = torch.normal(mean = 0, std = 1, size = (8,4), requires_grad = True, dtype = torch.float64)\n",
    "w2 = torch.normal(mean = 0, std = 1, size = (4,1), requires_grad = True, dtype = torch.float64)\n",
    "params = [w1, w2]\n",
    "layers = ['sigmoid', 'ReLu']\n",
    "solver = SRW_pytorch(n_iter, lambda_value, beta, group_labels, features, edges, P_init, nnodes, layers, params, rst_prob, lr, \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, accuracy = solver.validation(features, edges, P_init, group_labels)\n",
    "print(\"validation loss: %.4f\\t validation_accuracy: %.4f\" %(loss_value.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
