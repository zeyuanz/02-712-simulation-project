{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100\n",
    "nnodes = 1000\n",
    "edge_freq = 0.004\n",
    "cliq_edge_freq = 0.114\n",
    "hi_mut_freq = 0.5\n",
    "hi_node = nnodes*3/4\n",
    "group_labels = ['Subtype 1']*(nsamples//2) + ['Subtype 2']*(nsamples//2)\n",
    "feature_names = ['Subnetwork 1', 'Subnetwork 2', 'High mut source', 'High mut target', \n",
    "                 'Random 1', 'Random 2', \n",
    "                 'Self loop', 'Intercept']\n",
    "node_names = ['{}'.format(i) for i in range(1,nnodes+1)]\n",
    "sample_names = ['{}'.format(i) for i in range(1,nsamples+1)]\n",
    "\n",
    "rand_mut_freq = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [0]*nnodes\n",
    "edges = []\n",
    "features = [] #(11) cliq1, cliq2, hi_mut_source, hi_mut_target, rand1, rand2, rand3, rand4, rand5, self_loop, intercept\n",
    "for i in range(nnodes-1):\n",
    "    for j in range(i+1,nnodes):\n",
    "        if ((i<100 and j<100) and np.random.random()<cliq_edge_freq) or np.random.random()<edge_freq:\n",
    "            edges.append([i,j])\n",
    "            edges.append([j,i])\n",
    "            features.append([0,0,0,0,np.random.random(),np.random.random(),0,1])\n",
    "            features.append([0,0,0,0,np.random.random(),np.random.random(),0,1])\n",
    "            if (i<50 and j<50):\n",
    "                features[-2][0] = 1\n",
    "                features[-1][0] = 1\n",
    "            if (i>=50 and i<100 and j>=50 and j<100):\n",
    "                features[-2][1] = 1\n",
    "                features[-1][1] = 1\n",
    "            if i == nnodes-1:\n",
    "                features[-2][2] = 1\n",
    "                features[-1][3] = 1\n",
    "            if j == nnodes-1:\n",
    "                features[-2][3] = 1\n",
    "                features[-1][2] = 1\n",
    "            degrees[i] += 1\n",
    "            degrees[j] += 1\n",
    "            \n",
    "\n",
    "for i in range(nnodes):\n",
    "    edges.append([i,i])\n",
    "    features.append([0,0,0,0,np.random.random(),np.random.random(),1,1])\n",
    "\n",
    "P_init = []\n",
    "for p in range(nsamples):\n",
    "    p_init = []\n",
    "    for i in range(nnodes):\n",
    "        freq=0\n",
    "        if p == i:\n",
    "            freq = 1\n",
    "        elif i == hi_node:\n",
    "            freq = hi_mut_freq\n",
    "        elif i<100:\n",
    "            if (max(p,i)<50 or min(p,i)>=50):\n",
    "                freq = 0.015\n",
    "            else:\n",
    "                freq = 0.000\n",
    "        else:\n",
    "            freq = rand_mut_freq\n",
    "\n",
    "        if np.random.random() < freq:\n",
    "            p_init.append(1.0)\n",
    "        else:\n",
    "            p_init.append(0.0)\n",
    "\n",
    "    P_init.append(p_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_init = torch.tensor(P_init, requires_grad = True)\n",
    "features = torch.tensor(features, requires_grad = True, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_distinct_labels(group_labels):\n",
    "    '''\n",
    "    compute labels dictionary\n",
    "    {\n",
    "        'type 1': [sample_start_position_1, sample_end_position_1],\n",
    "        'type 2': [sample_start_position_2, sample_end_position_2],\n",
    "        ...\n",
    "    }\n",
    "    '''\n",
    "    all_labels = {}\n",
    "    for i, label in enumerate(group_labels):\n",
    "        if label not in all_labels:\n",
    "            all_labels[label] = [i]\n",
    "        if i == len(group_labels)-1 or group_labels[i+1] not in all_labels:\n",
    "            all_labels[label].append(i+1)\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centers_SRW(P, all_labels):\n",
    "    '''\n",
    "    compute group centers, adapted from SRW centroid() function\n",
    "    \n",
    "    return a tensor with group centroids\n",
    "    if we have k groups and n nodes, then C.shape = (k, n)\n",
    "    '''\n",
    "    C = torch.zeros(size=(len(all_labels), P.shape[1]))\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        start, end = all_labels[label]\n",
    "        C[count,:] = torch.sum(P[start: end, :], axis = 0) / (end - start)\n",
    "        count += 1\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_id(all_labels):\n",
    "    '''\n",
    "    mapping label string to id\n",
    "     {\n",
    "        'type 1': 0,\n",
    "        'type 2': 1,\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    label_id = {}\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        label_id[label] = count\n",
    "        count += 1\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(lambda_value, w, beta, P, group_labels, all_labels, is_train):\n",
    "    '''\n",
    "    compute loss function adapted from SRW cost_func_WMW()\n",
    "    '''\n",
    "    '''l1 norm'''\n",
    "    loss_value = lambda_value * torch.norm(w, p=1)\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    '''retrieve centers'''\n",
    "    C = calculate_centers_SRW(P, all_labels)\n",
    "    \n",
    "    '''retrieve ids for group labels'''\n",
    "    label_id = label_to_id(all_labels)\n",
    "    \n",
    "    '''necessary intermediate value for computing loss'''\n",
    "    P_dot_CT = torch.matmul(P, C.T)\n",
    "    C_dot_CT = torch.matmul(C, C.T)\n",
    "    P_dot_PT = torch.matmul(P, P.T)\n",
    "    \n",
    "    '''simply copy from SRW cost_func_WMW()'''\n",
    "    for u in range(P.shape[0]):\n",
    "        x_u = torch.tensor(-2.0)\n",
    "        i = label_id[group_labels[u]]\n",
    "        start, end = all_labels[group_labels[u]]\n",
    "        group_sample = end - start\n",
    "        if is_train == False:\n",
    "            coeff = (group_sample / (group_sample - 1)) ** 2\n",
    "        else:\n",
    "            coeff = 1.0\n",
    "        dist_ui = coeff *( P_dot_PT[u,u] -2 * P_dot_CT[u, i] + C_dot_CT[i,i])\n",
    "        for label in label_id:\n",
    "            if label != group_labels[u]:\n",
    "                j = label_id[label]\n",
    "                x_u_tmp = dist_ui -(P_dot_PT[u,u] - 2*P_dot_CT[u,j] + C_dot_CT[j,j])\n",
    "                if x_u_tmp > x_u:\n",
    "                    x_u = x_u_tmp\n",
    "        '''if correctly classified, increase accuracy'''\n",
    "        if x_u < 0.0:\n",
    "            accuracy += 1.0\n",
    "        loss_value += 1. / (1+torch.exp(-x_u / beta))\n",
    "    return loss_value, accuracy / P.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class implement with pytorch\n",
    "* train with simple gradient descent\n",
    "* add validation module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRW_pytorch:\n",
    "    def __init__(self, n_iter, lambda_value, beta, group_labels, features, edges, P, nnodes, rst_prob, lr):\n",
    "        self.n_iter = n_iter\n",
    "        self.lambda_value = lambda_value\n",
    "        self.beta = beta\n",
    "        self.group_labels = group_labels\n",
    "        self.features = features\n",
    "        self.edges = edges\n",
    "        self.P = P\n",
    "        self.nnodes = nnodes\n",
    "        self.rst_prob = rst_prob\n",
    "        self.lr = lr\n",
    "        self.is_train = False\n",
    "        self.w = None\n",
    "        self.Q_final = None\n",
    "        \n",
    "    def train(self):\n",
    "        w = torch.normal(mean = 0, std = 1, size=(features.shape[1],1), requires_grad = True, dtype=torch.float64)\n",
    "        for i in range(n_iter):\n",
    "            '''compute edge strength, sigmoid activation'''\n",
    "            strength = 1.0 / (1.0 + torch.exp(-torch.matmul(self.features, w)))\n",
    "\n",
    "            '''create transition matrix Q'''\n",
    "            Q = torch.zeros(size=(self.nnodes, self.nnodes))\n",
    "            for j in range(strength.shape[0]):\n",
    "                Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
    "\n",
    "            '''normalize Q'''\n",
    "            Q = Q / (torch.sum(Q, axis = 1) + 1e-8).reshape(-1,1)\n",
    "            self.Q_final = Q\n",
    "            \n",
    "            '''noramlize P'''\n",
    "            P_init = self.P / (torch.sum(self.P, axis = 1) + 1e-8).reshape(-1,1)\n",
    "\n",
    "            '''create P matrix for random walk'''\n",
    "            P = torch.detach(P_init)\n",
    "            P.requires_grad = True\n",
    "\n",
    "            '''for test, only peform random walk 30 times (should be enough to converge)''' \n",
    "            for j in range(30):\n",
    "                P = (1-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
    "\n",
    "            '''compute loss and backward()'''\n",
    "            all_labels = extract_distinct_labels(self.group_labels)\n",
    "            loss_value, accuracy = loss(self.lambda_value, w, self.beta, P, self.group_labels, all_labels, self.is_train)\n",
    "            loss_value.backward(retain_graph = True)\n",
    "\n",
    "            '''simple GD optimization'''\n",
    "            with torch.no_grad():\n",
    "                w -= self.lr * w.grad\n",
    "                self.w = w\n",
    "            \n",
    "            '''zero grad'''\n",
    "            w.grad.zero_()\n",
    "            print(\"[%d/%d] training loss: %.4f\\t training accuracy: %.4f\" %(i+1, n_iter, loss_value.data, accuracy))\n",
    "        self.is_train = True\n",
    "    \n",
    "    def validation(self, P_validation, group_labels_validation):\n",
    "        if self.is_train == False:\n",
    "            print(\"You should train the model first\")\n",
    "            return\n",
    "        \n",
    "        P = torch.detach(P_validation)\n",
    "        Q_final = self.Q_final\n",
    "        for j in range(30):\n",
    "                P = (1-self.rst_prob) * (torch.matmul(P,Q_final)) + self.rst_prob * P_validation\n",
    "        \n",
    "        all_labels = extract_distinct_labels(group_labels_validation)\n",
    "        loss_value, accuracy = loss(self.lambda_value, self.w, self.beta, P, group_labels_validation, all_labels, self.is_train)\n",
    "        \n",
    "        return loss_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "lambda_value = 0.1\n",
    "beta = 2e-4\n",
    "rst_prob = 0.3\n",
    "lr = 1.0\n",
    "solver = SRW_pytorch(n_iter, lambda_value, beta, group_labels, features, edges, P_init, nnodes, rst_prob, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] training loss: 46.6808\t training accuracy: 0.5700\n",
      "[2/10] training loss: 45.7408\t training accuracy: 0.5800\n",
      "[3/10] training loss: 45.4708\t training accuracy: 0.5800\n",
      "[4/10] training loss: 45.3632\t training accuracy: 0.5800\n",
      "[5/10] training loss: 45.2260\t training accuracy: 0.5800\n",
      "[6/10] training loss: 45.0049\t training accuracy: 0.5800\n",
      "[7/10] training loss: 44.5474\t training accuracy: 0.5900\n"
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, accuracy = solver.validation(P_init, group_labels)\n",
    "print(\"validation loss: %.4f\\t validation_accuracy: %.4f\" %(loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
